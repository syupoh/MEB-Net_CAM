         Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 128]           9,408
       BatchNorm2d-2         [-1, 64, 112, 128]             128
         MaxPool2d-3           [-1, 64, 56, 64]               0
            Conv2d-4           [-1, 64, 56, 64]           4,096
       BatchNorm2d-5           [-1, 64, 56, 64]             128
              ReLU-6           [-1, 64, 56, 64]               0
            Conv2d-7           [-1, 64, 56, 64]          36,864
       BatchNorm2d-8           [-1, 64, 56, 64]             128
              ReLU-9           [-1, 64, 56, 64]               0
           Conv2d-10          [-1, 256, 56, 64]          16,384
      BatchNorm2d-11          [-1, 256, 56, 64]             512
           Conv2d-12          [-1, 256, 56, 64]          16,384
      BatchNorm2d-13          [-1, 256, 56, 64]             512
             ReLU-14          [-1, 256, 56, 64]               0
       Bottleneck-15          [-1, 256, 56, 64]               0
           Conv2d-16           [-1, 64, 56, 64]          16,384
      BatchNorm2d-17           [-1, 64, 56, 64]             128
             ReLU-18           [-1, 64, 56, 64]               0
           Conv2d-19           [-1, 64, 56, 64]          36,864
      BatchNorm2d-20           [-1, 64, 56, 64]             128
             ReLU-21           [-1, 64, 56, 64]               0
           Conv2d-22          [-1, 256, 56, 64]          16,384
      BatchNorm2d-23          [-1, 256, 56, 64]             512
             ReLU-24          [-1, 256, 56, 64]               0
       Bottleneck-25          [-1, 256, 56, 64]               0
           Conv2d-26           [-1, 64, 56, 64]          16,384
      BatchNorm2d-27           [-1, 64, 56, 64]             128
             ReLU-28           [-1, 64, 56, 64]               0
           Conv2d-29           [-1, 64, 56, 64]          36,864
      BatchNorm2d-30           [-1, 64, 56, 64]             128
             ReLU-31           [-1, 64, 56, 64]               0
           Conv2d-32          [-1, 256, 56, 64]          16,384
      BatchNorm2d-33          [-1, 256, 56, 64]             512
             ReLU-34          [-1, 256, 56, 64]               0
       Bottleneck-35          [-1, 256, 56, 64]               0
           Conv2d-36          [-1, 128, 56, 64]          32,768
      BatchNorm2d-37          [-1, 128, 56, 64]             256
             ReLU-38          [-1, 128, 56, 64]               0
           Conv2d-39          [-1, 128, 28, 32]         147,456
      BatchNorm2d-40          [-1, 128, 28, 32]             256
             ReLU-41          [-1, 128, 28, 32]               0
           Conv2d-42          [-1, 512, 28, 32]          65,536
      BatchNorm2d-43          [-1, 512, 28, 32]           1,024
           Conv2d-44          [-1, 512, 28, 32]         131,072
      BatchNorm2d-45          [-1, 512, 28, 32]           1,024
             ReLU-46          [-1, 512, 28, 32]               0
       Bottleneck-47          [-1, 512, 28, 32]               0
           Conv2d-48          [-1, 128, 28, 32]          65,536
      BatchNorm2d-49          [-1, 128, 28, 32]             256
             ReLU-50          [-1, 128, 28, 32]               0
           Conv2d-51          [-1, 128, 28, 32]         147,456
      BatchNorm2d-52          [-1, 128, 28, 32]             256
             ReLU-53          [-1, 128, 28, 32]               0
           Conv2d-54          [-1, 512, 28, 32]          65,536
      BatchNorm2d-55          [-1, 512, 28, 32]           1,024
             ReLU-56          [-1, 512, 28, 32]               0
       Bottleneck-57          [-1, 512, 28, 32]               0
           Conv2d-58          [-1, 128, 28, 32]          65,536
      BatchNorm2d-59          [-1, 128, 28, 32]             256
             ReLU-60          [-1, 128, 28, 32]               0
           Conv2d-61          [-1, 128, 28, 32]         147,456
      BatchNorm2d-62          [-1, 128, 28, 32]             256
             ReLU-63          [-1, 128, 28, 32]               0
           Conv2d-64          [-1, 512, 28, 32]          65,536
      BatchNorm2d-65          [-1, 512, 28, 32]           1,024
             ReLU-66          [-1, 512, 28, 32]               0
       Bottleneck-67          [-1, 512, 28, 32]               0
           Conv2d-68          [-1, 128, 28, 32]          65,536
      BatchNorm2d-69          [-1, 128, 28, 32]             256
             ReLU-70          [-1, 128, 28, 32]               0
           Conv2d-71          [-1, 128, 28, 32]         147,456
      BatchNorm2d-72          [-1, 128, 28, 32]             256
             ReLU-73          [-1, 128, 28, 32]               0
           Conv2d-74          [-1, 512, 28, 32]          65,536
      BatchNorm2d-75          [-1, 512, 28, 32]           1,024
             ReLU-76          [-1, 512, 28, 32]               0
       Bottleneck-77          [-1, 512, 28, 32]               0
           Conv2d-78          [-1, 256, 28, 32]         131,072
      BatchNorm2d-79          [-1, 256, 28, 32]             512
             ReLU-80          [-1, 256, 28, 32]               0
          Conv2d-81          [-1, 256, 14, 16]         589,824
      BatchNorm2d-82          [-1, 256, 14, 16]             512
             ReLU-83          [-1, 256, 14, 16]               0
           Conv2d-84         [-1, 1024, 14, 16]         262,144
      BatchNorm2d-85         [-1, 1024, 14, 16]           2,048
           Conv2d-86         [-1, 1024, 14, 16]         524,288
      BatchNorm2d-87         [-1, 1024, 14, 16]           2,048
             ReLU-88         [-1, 1024, 14, 16]               0
       Bottleneck-89         [-1, 1024, 14, 16]               0
           Conv2d-90          [-1, 256, 14, 16]         262,144
      BatchNorm2d-91          [-1, 256, 14, 16]             512
             ReLU-92          [-1, 256, 14, 16]               0
           Conv2d-93          [-1, 256, 14, 16]         589,824
      BatchNorm2d-94          [-1, 256, 14, 16]             512
             ReLU-95          [-1, 256, 14, 16]               0
           Conv2d-96         [-1, 1024, 14, 16]         262,144
      BatchNorm2d-97         [-1, 1024, 14, 16]           2,048
             ReLU-98         [-1, 1024, 14, 16]               0
       Bottleneck-99         [-1, 1024, 14, 16]               0
          Conv2d-100          [-1, 256, 14, 16]         262,144
     BatchNorm2d-101          [-1, 256, 14, 16]             512
            ReLU-102          [-1, 256, 14, 16]               0
          Conv2d-103          [-1, 256, 14, 16]         589,824
     BatchNorm2d-104          [-1, 256, 14, 16]             512
            ReLU-105          [-1, 256, 14, 16]               0
          Conv2d-106         [-1, 1024, 14, 16]         262,144
     BatchNorm2d-107         [-1, 1024, 14, 16]           2,048
            ReLU-108         [-1, 1024, 14, 16]               0
      Bottleneck-109         [-1, 1024, 14, 16]               0
          Conv2d-110          [-1, 256, 14, 16]         262,144
     BatchNorm2d-111          [-1, 256, 14, 16]             512
            ReLU-112          [-1, 256, 14, 16]               0
          Conv2d-113          [-1, 256, 14, 16]         589,824
     BatchNorm2d-114          [-1, 256, 14, 16]             512
            ReLU-115          [-1, 256, 14, 16]               0
          Conv2d-116         [-1, 1024, 14, 16]         262,144
     BatchNorm2d-117         [-1, 1024, 14, 16]           2,048
            ReLU-118         [-1, 1024, 14, 16]               0
      Bottleneck-119         [-1, 1024, 14, 16]               0
          Conv2d-120          [-1, 256, 14, 16]         262,144
     BatchNorm2d-121          [-1, 256, 14, 16]             512
            ReLU-122          [-1, 256, 14, 16]               0
          Conv2d-123          [-1, 256, 14, 16]         589,824
     BatchNorm2d-124          [-1, 256, 14, 16]             512
            ReLU-125          [-1, 256, 14, 16]               0
          Conv2d-126         [-1, 1024, 14, 16]         262,144
     BatchNorm2d-127         [-1, 1024, 14, 16]           2,048
            ReLU-128         [-1, 1024, 14, 16]               0
      Bottleneck-129         [-1, 1024, 14, 16]               0
          Conv2d-130          [-1, 256, 14, 16]         262,144
     BatchNorm2d-131          [-1, 256, 14, 16]             512
            ReLU-132          [-1, 256, 14, 16]               0
          Conv2d-133          [-1, 256, 14, 16]         589,824
     BatchNorm2d-134          [-1, 256, 14, 16]             512
            ReLU-135          [-1, 256, 14, 16]               0
          Conv2d-136         [-1, 1024, 14, 16]         262,144
     BatchNorm2d-137         [-1, 1024, 14, 16]           2,048
            ReLU-138         [-1, 1024, 14, 16]               0
      Bottleneck-139         [-1, 1024, 14, 16]               0
          Conv2d-140          [-1, 512, 14, 16]         524,288
     BatchNorm2d-141          [-1, 512, 14, 16]           1,024
            ReLU-142          [-1, 512, 14, 16]               0
          Conv2d-143          [-1, 512, 14, 16]       2,359,296
     BatchNorm2d-144          [-1, 512, 14, 16]           1,024
            ReLU-145          [-1, 512, 14, 16]               0
          Conv2d-146         [-1, 2048, 14, 16]       1,048,576
     BatchNorm2d-147         [-1, 2048, 14, 16]           4,096
          Conv2d-148         [-1, 2048, 14, 16]       2,097,152
     BatchNorm2d-149         [-1, 2048, 14, 16]           4,096
            ReLU-150         [-1, 2048, 14, 16]               0
      Bottleneck-151         [-1, 2048, 14, 16]               0
          Conv2d-152          [-1, 512, 14, 16]       1,048,576
     BatchNorm2d-153          [-1, 512, 14, 16]           1,024
            ReLU-154          [-1, 512, 14, 16]               0
          Conv2d-155          [-1, 512, 14, 16]       2,359,296
     BatchNorm2d-156          [-1, 512, 14, 16]           1,024
            ReLU-157          [-1, 512, 14, 16]               0
          Conv2d-158         [-1, 2048, 14, 16]       1,048,576
     BatchNorm2d-159         [-1, 2048, 14, 16]           4,096
            ReLU-160         [-1, 2048, 14, 16]               0
      Bottleneck-161         [-1, 2048, 14, 16]               0
          Conv2d-162          [-1, 512, 14, 16]       1,048,576
     BatchNorm2d-163          [-1, 512, 14, 16]           1,024
            ReLU-164          [-1, 512, 14, 16]               0
          Conv2d-165          [-1, 512, 14, 16]       2,359,296
     BatchNorm2d-166          [-1, 512, 14, 16]           1,024
            ReLU-167          [-1, 512, 14, 16]               0
          Conv2d-168         [-1, 2048, 14, 16]       1,048,576
     BatchNorm2d-169         [-1, 2048, 14, 16]           4,096
            ReLU-170         [-1, 2048, 14, 16]               0
      Bottleneck-171         [-1, 2048, 14, 16]               0
AdaptiveAvgPool2d-172           [-1, 2048, 1, 1]               0
     BatchNorm1d-173                 [-1, 2048]           4,096
          Linear-174                  [-1, 702]       1,437,696
================================================================



=============================
=============================
=============================
== Start ==
Block: 0 Curr shape: torch.Size([2, 3, 256, 128])
Block: 1 Out shape: torch.Size([2, 64, 128, 64]); features shape: torch.Size([2, 64, 256, 128])
Block: 2 Out shape: torch.Size([2, 128, 64, 32]); features shape: torch.Size([2, 128, 128, 64])
Block: 3 Out shape: torch.Size([2, 256, 32, 16]); features shape: torch.Size([2, 256, 64, 32])
Block: 4 Out shape: torch.Size([2, 512, 16, 8]); features shape: torch.Size([2, 512, 32, 16])
torch.Size([2, 512, 16, 8])
Block: 5 Out shape: torch.Size([2, 512, 32, 16])
Block: 6 Out shape: torch.Size([2, 256, 64, 32])
Block: 7 Out shape: torch.Size([2, 128, 128, 64])
Block: 8 Out shape: torch.Size([2, 64, 256, 128])
Block: 9 Out shape: torch.Size([2, 3, 256, 128])
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 254, 126]           1,792
              ReLU-2         [-1, 64, 254, 126]               0
       BatchNorm2d-3         [-1, 64, 254, 126]             128
  ReplicationPad2d-4         [-1, 64, 256, 128]               0
            Conv2d-5         [-1, 64, 254, 126]          36,928
              ReLU-6         [-1, 64, 254, 126]               0
       BatchNorm2d-7         [-1, 64, 254, 126]             128
  ReplicationPad2d-8         [-1, 64, 256, 128]               0
         MaxPool2d-9          [-1, 64, 128, 64]               0
WNetDownConvBlock-10  [[-1, 64, 128, 64], [-1, 64, 256, 128]]               0
           Conv2d-11         [-1, 128, 126, 62]          73,856
             ReLU-12         [-1, 128, 126, 62]               0
      BatchNorm2d-13         [-1, 128, 126, 62]             256
 ReplicationPad2d-14         [-1, 128, 128, 64]               0
           Conv2d-15         [-1, 128, 126, 62]         147,584
             ReLU-16         [-1, 128, 126, 62]               0
      BatchNorm2d-17         [-1, 128, 126, 62]             256
       ReplicationPad2d-18         [-1, 128, 128, 64]               0
        MaxPool2d-19          [-1, 128, 64, 32]               0
WNetDownConvBlock-20  [[-1, 128, 64, 32], [-1, 128, 128, 64]]               0
           Conv2d-21          [-1, 256, 62, 30]         295,168
             ReLU-22          [-1, 256, 62, 30]               0
      BatchNorm2d-23          [-1, 256, 62, 30]             512
 ReplicationPad2d-24          [-1, 256, 64, 32]               0
           Conv2d-25          [-1, 256, 62, 30]         590,080
             ReLU-26          [-1, 256, 62, 30]               0
      BatchNorm2d-27          [-1, 256, 62, 30]             512
 ReplicationPad2d-28          [-1, 256, 64, 32]               0
        MaxPool2d-29          [-1, 256, 32, 16]               0
WNetDownConvBlock-30  [[-1, 256, 32, 16], [-1, 256, 64, 32]]               0
           Conv2d-31          [-1, 512, 30, 14]       1,180,160
             ReLU-32          [-1, 512, 30, 14]               0
      BatchNorm2d-33          [-1, 512, 30, 14]           1,024
 ReplicationPad2d-34          [-1, 512, 32, 16]               0
           Conv2d-35          [-1, 512, 30, 14]       2,359,808
             ReLU-36          [-1, 512, 30, 14]               0
      BatchNorm2d-37          [-1, 512, 30, 14]           1,024
 ReplicationPad2d-38          [-1, 512, 32, 16]               0
        MaxPool2d-39           [-1, 512, 16, 8]               0
WNetDownConvBlock-40  [[-1, 512, 16, 8], [-1, 512, 32, 16]]               0
           Conv2d-41          [-1, 1024, 14, 6]       4,719,616
      BatchNorm2d-42          [-1, 1024, 14, 6]           2,048
             ReLU-43          [-1, 1024, 14, 6]               0
 ReplicationPad2d-44          [-1, 1024, 16, 8]               0
           Conv2d-45          [-1, 1024, 14, 6]       9,438,208
      BatchNorm2d-46          [-1, 1024, 14, 6]           2,048
             ReLU-47          [-1, 1024, 14, 6]               0
 ReplicationPad2d-48          [-1, 1024, 16, 8]               0
  ConvTranspose2d-49          [-1, 512, 32, 16]       2,097,664
  WNetUpConvBlock-50          [-1, 512, 32, 16]               0
           Conv2d-51          [-1, 512, 30, 14]       4,719,104
      BatchNorm2d-52          [-1, 512, 30, 14]           1,024
             ReLU-53          [-1, 512, 30, 14]               0
 ReplicationPad2d-54          [-1, 512, 32, 16]               0
           Conv2d-55          [-1, 512, 30, 14]       2,359,808
      BatchNorm2d-56          [-1, 512, 30, 14]           1,024
             ReLU-57          [-1, 512, 30, 14]               0
ReplicationPad2d-58          [-1, 512, 32, 16]               0
  ConvTranspose2d-59          [-1, 256, 64, 32]         524,544
  WNetUpConvBlock-60          [-1, 256, 64, 32]               0
           Conv2d-61          [-1, 256, 62, 30]       1,179,904
      BatchNorm2d-62          [-1, 256, 62, 30]             512
             ReLU-63          [-1, 256, 62, 30]               0
 ReplicationPad2d-64          [-1, 256, 64, 32]               0
           Conv2d-65          [-1, 256, 62, 30]         590,080
      BatchNorm2d-66          [-1, 256, 62, 30]             512
             ReLU-67          [-1, 256, 62, 30]               0
 ReplicationPad2d-68          [-1, 256, 64, 32]               0
  ConvTranspose2d-69         [-1, 128, 128, 64]         131,200
  WNetUpConvBlock-70         [-1, 128, 128, 64]               0
           Conv2d-71         [-1, 128, 126, 62]         295,040
      BatchNorm2d-72         [-1, 128, 126, 62]             256
             ReLU-73         [-1, 128, 126, 62]               0
 ReplicationPad2d-74         [-1, 128, 128, 64]               0
           Conv2d-75         [-1, 128, 126, 62]         147,584
      BatchNorm2d-76         [-1, 128, 126, 62]             256
             ReLU-77         [-1, 128, 126, 62]               0
 ReplicationPad2d-78         [-1, 128, 128, 64]               0
  ConvTranspose2d-79         [-1, 64, 256, 128]          32,832
  WNetUpConvBlock-80         [-1, 64, 256, 128]               0
           Conv2d-81         [-1, 64, 254, 126]          73,792
      BatchNorm2d-82         [-1, 64, 254, 126]             128
             ReLU-83         [-1, 64, 254, 126]               0
 ReplicationPad2d-84         [-1, 64, 256, 128]               0
           Conv2d-85         [-1, 64, 254, 126]          36,928
      BatchNorm2d-86         [-1, 64, 254, 126]             128
             ReLU-87         [-1, 64, 254, 126]               0
 ReplicationPad2d-88         [-1, 64, 256, 128]               0
           Conv2d-89          [-1, 3, 256, 128]             195
  WNetOutputBlock-90          [-1, 3, 256, 128]               0
================================================================
Total params: 31,043,651
Trainable params: 31,043,651
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 11140582.71
Params size (MB): 118.42
Estimated Total Size (MB): 11140701.51
----------------------------------------------------------------
== End ==


